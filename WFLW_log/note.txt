/content/drive/MyDrive/colab/star
mode is train, config_name is alignment, pretrained_weight is None, image_dir is /content/drive/MyDrive/colab/dataset_for_STAR/image_dir, annot_dir is /content/drive/MyDrive/colab/dataset_for_STAR/annot_dir, device_ids is 0
/usr/local/lib/python3.10/dist-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
2024-01-04 19:33:20,327 INFO    : 
type: alignment
id: 4364df98-c96c-488b-ab42-3eafad0a02ad
note: 
ckpt_dir: /apdcephfs_cq3/share_1134483/charlinzhou/ckpts/STAR/
image_dir: /content/drive/MyDrive/colab/dataset_for_STAR/image_dir/WFLW/WFLW_images
annot_dir: /content/drive/MyDrive/colab/dataset_for_STAR/annot_dir
loader_type: alignment
loss_func: STARLoss_v2
batch_size: 8
val_batch_size: 32
test_batch_size: 16
channels: 3
width: 256
height: 256
means: (127.5, 127.5, 127.5)
scale: 0.00784313725490196
display_iteration: 10
milestones: [200, 350, 450]
max_epoch: 1
net: stackedHGnet_v1
nstack: 4
optimizer: adam
learn_rate: 0.001
momentum: 0.01
weight_decay: 1e-05
nesterov: False
scheduler: MultiStepLR
gamma: 0.1
loss_weights: [0.125, 1.25, 1.25, 0.25, 2.5, 2.5, 0.5, 5.0, 5.0, 1.0, 10.0, 10.0]
criterions: ['STARLoss_v2', 'AWingLoss', 'AWingLoss', 'STARLoss_v2', 'AWingLoss', 'AWingLoss', 'STARLoss_v2', 'AWingLoss', 'AWingLoss', 'STARLoss_v2', 'AWingLoss', 'AWingLoss']
metrics: ['NME', None, None, 'NME', None, None, 'NME', None, None, 'NME', None, None]
key_metric_index: 9
classes_num: [98, 9, 98]
label_num: 12
ema: True
use_AAM: True
writer: <tensorboardX.writer.SummaryWriter object at 0x7dfc7f29e1a0>
logger: <RootLogger root (NOTSET)>
data_definition: WFLW
test_file: test.tsv
aug_prob: 1.0
val_epoch: 1
valset: test.tsv
norm_type: default
encoder_type: default
decoder_type: default
betas: [0.9, 0.999]
train_num_workers: 16
val_num_workers: 16
test_num_workers: 0
add_coord: True
star_w: 1
star_dist: smoothl1
edge_info: ((False, (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32)), (True, (33, 34, 35, 36, 37, 38, 39, 40, 41)), (True, (42, 43, 44, 45, 46, 47, 48, 49, 50)), (False, (51, 52, 53, 54)), (False, (55, 56, 57, 58, 59)), (True, (60, 61, 62, 63, 64, 65, 66, 67)), (True, (68, 69, 70, 71, 72, 73, 74, 75)), (True, (76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87)), (True, (88, 89, 90, 91, 92, 93, 94, 95)))
nme_left_index: 60
nme_right_index: 72
crop_op: True
flip_mapping: ([0, 32], [1, 31], [2, 30], [3, 29], [4, 28], [5, 27], [6, 26], [7, 25], [8, 24], [9, 23], [10, 22], [11, 21], [12, 20], [13, 19], [14, 18], [15, 17], [33, 46], [34, 45], [35, 44], [36, 43], [37, 42], [38, 50], [39, 49], [40, 48], [41, 47], [60, 72], [61, 71], [62, 70], [63, 69], [64, 68], [65, 75], [66, 74], [67, 73], [55, 59], [56, 58], [76, 82], [77, 81], [78, 80], [87, 83], [86, 84], [88, 92], [89, 91], [95, 93], [96, 97])
folder: WFLW_256x256_adam_ep1_lr0.001_bs8_STARLoss_v2_AAM_4364df98-c96c-488b-ab42-3eafad0a02ad
work_dir: /apdcephfs_cq3/share_1134483/charlinzhou/ckpts/STAR/WFLW/WFLW_256x256_adam_ep1_lr0.001_bs8_STARLoss_v2_AAM_4364df98-c96c-488b-ab42-3eafad0a02ad
model_dir: /apdcephfs_cq3/share_1134483/charlinzhou/ckpts/STAR/WFLW/WFLW_256x256_adam_ep1_lr0.001_bs8_STARLoss_v2_AAM_4364df98-c96c-488b-ab42-3eafad0a02ad/model
log_dir: /apdcephfs_cq3/share_1134483/charlinzhou/ckpts/STAR/WFLW/WFLW_256x256_adam_ep1_lr0.001_bs8_STARLoss_v2_AAM_4364df98-c96c-488b-ab42-3eafad0a02ad/log
train_tsv_file: /content/drive/MyDrive/colab/dataset_for_STAR/annot_dir/WFLW/train.tsv
train_pic_dir: /content/drive/MyDrive/colab/dataset_for_STAR/image_dir/WFLW/WFLW_images
val_tsv_file: /content/drive/MyDrive/colab/dataset_for_STAR/annot_dir/WFLW/test.tsv
val_pic_dir: /content/drive/MyDrive/colab/dataset_for_STAR/image_dir/WFLW/WFLW_images
test_tsv_file: /content/drive/MyDrive/colab/dataset_for_STAR/annot_dir/WFLW/test.tsv
test_pic_dir: /content/drive/MyDrive/colab/dataset_for_STAR/image_dir/WFLW/WFLW_images
device_id: 0
device: cuda:0
use_gpu: True
2024-01-04 19:33:20,327 INFO    : Loaded configure file alignment: 4364df98-c96c-488b-ab42-3eafad0a02ad
2024-01-04 19:33:21,382 INFO    : Loaded network
/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
2024-01-04 19:33:21,669 INFO    : Loaded data
2024-01-04 19:33:21,669 INFO    : Optimizer type adam. Start training...
2024-01-04 19:33:21,669 INFO    : Train/Epoch: 0/1, Learning rate decays to [0.001], [Time Left: 00:00:00]eval_time: 0.00, 


2024-01-04 19:33:21,687 INFO    : 
2024-01-04 19:33:21,687 INFO    : Forward Backward process, Dataset size: 7499, Batch size: 8
/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/content/drive/MyDrive/colab/star/lib/utility.py:288: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
2024-01-04 19:33:52,386 INFO    :  -->>[001/001][000/938][Time Left: 04:48:57] Average Loss: 3.111999, L0: 2.579, L1: 3.139, L2: 3.818, L3: 2.598, L4: 3.019, L5: 3.562, L6: 2.572, L7: 3.056, L8: 3.758, L9: 2.625, L10: 3.086, L11: 3.533
2024-01-04 19:34:11,945 INFO    :  -->>[001/001][010/938][Time Left: 00:53:15] Average Loss: 1.459733, L0: 2.796, L1: 1.240, L2: 1.303, L3: 2.634, L4: 0.920, L5: 0.993, L6: 2.166, L7: 0.882, L8: 1.010, L9: 1.774, L10: 0.922, L11: 0.875
2024-01-04 19:34:31,187 INFO    :  -->>[001/001][020/938][Time Left: 00:41:30] Average Loss: 0.899039, L0: 2.834, L1: 0.307, L2: 0.422, L3: 2.295, L4: 0.175, L5: 0.329, L6: 1.852, L7: 0.143, L8: 0.313, L9: 1.671, L10: 0.145, L11: 0.303
2024-01-04 19:34:50,322 INFO    :  -->>[001/001][030/938][Time Left: 00:37:05] Average Loss: 0.783291, L0: 2.524, L1: 0.100, L2: 0.276, L3: 2.016, L4: 0.058, L5: 0.250, L6: 1.832, L7: 0.049, L8: 0.245, L9: 1.754, L10: 0.050, L11: 0.244
2024-01-04 19:35:09,323 INFO    :  -->>[001/001][040/938][Time Left: 00:34:37] Average Loss: 0.681658, L0: 2.137, L1: 0.054, L2: 0.240, L3: 1.719, L4: 0.037, L5: 0.232, L6: 1.648, L7: 0.034, L8: 0.230, L9: 1.586, L10: 0.034, L11: 0.229
2024-01-04 19:35:28,530 INFO    :  -->>[001/001][050/938][Time Left: 00:33:03] Average Loss: 0.656640, L0: 1.938, L1: 0.040, L2: 0.251, L3: 1.645, L4: 0.030, L5: 0.246, L6: 1.610, L7: 0.028, L8: 0.246, L9: 1.572, L10: 0.028, L11: 0.245
2024-01-04 19:35:47,654 INFO    :  -->>[001/001][060/938][Time Left: 00:31:52] Average Loss: 0.533116, L0: 1.580, L1: 0.034, L2: 0.229, L3: 1.321, L4: 0.026, L5: 0.226, L6: 1.246, L7: 0.025, L8: 0.225, L9: 1.235, L10: 0.025, L11: 0.225
2024-01-04 19:36:06,881 INFO    :  -->>[001/001][070/938][Time Left: 00:30:58] Average Loss: 0.567172, L0: 1.641, L1: 0.031, L2: 0.229, L3: 1.439, L4: 0.025, L5: 0.226, L6: 1.359, L7: 0.024, L8: 0.226, L9: 1.356, L10: 0.024, L11: 0.225
2024-01-04 19:36:25,887 INFO    :  -->>[001/001][080/938][Time Left: 00:30:09] Average Loss: 0.600416, L0: 1.705, L1: 0.029, L2: 0.226, L3: 1.551, L4: 0.024, L5: 0.223, L6: 1.485, L7: 0.023, L8: 0.223, L9: 1.471, L10: 0.023, L11: 0.223
2024-01-04 19:36:45,626 INFO    :  -->>[001/001][090/938][Time Left: 00:29:34] Average Loss: 0.588334, L0: 1.653, L1: 0.027, L2: 0.226, L3: 1.501, L4: 0.023, L5: 0.225, L6: 1.462, L7: 0.022, L8: 0.224, L9: 1.451, L10: 0.022, L11: 0.224
2024-01-04 19:37:04,908 INFO    :  -->>[001/001][100/938][Time Left: 00:28:58] Average Loss: 0.585878, L0: 1.589, L1: 0.025, L2: 0.218, L3: 1.492, L4: 0.022, L5: 0.216, L6: 1.486, L7: 0.022, L8: 0.216, L9: 1.507, L10: 0.022, L11: 0.216
2024-01-04 19:37:24,498 INFO    :  -->>[001/001][110/938][Time Left: 00:28:28] Average Loss: 0.550366, L0: 1.508, L1: 0.025, L2: 0.228, L3: 1.366, L4: 0.021, L5: 0.226, L6: 1.369, L7: 0.021, L8: 0.226, L9: 1.366, L10: 0.021, L11: 0.226
2024-01-04 19:37:43,414 INFO    :  -->>[001/001][120/938][Time Left: 00:27:55] Average Loss: 0.509061, L0: 1.415, L1: 0.024, L2: 0.218, L3: 1.254, L4: 0.021, L5: 0.216, L6: 1.243, L7: 0.021, L8: 0.217, L9: 1.243, L10: 0.021, L11: 0.216
2024-01-04 19:38:02,290 INFO    :  -->>[001/001][130/938][Time Left: 00:27:23] Average Loss: 0.473556, L0: 1.267, L1: 0.023, L2: 0.225, L3: 1.165, L4: 0.020, L5: 0.225, L6: 1.144, L7: 0.020, L8: 0.225, L9: 1.124, L10: 0.020, L11: 0.224
2024-01-04 19:38:21,078 INFO    :  -->>[001/001][140/938][Time Left: 00:26:53] Average Loss: 0.672262, L0: 1.769, L1: 0.023, L2: 0.208, L3: 1.797, L4: 0.020, L5: 0.206, L6: 1.798, L7: 0.020, L8: 0.206, L9: 1.795, L10: 0.020, L11: 0.205
2024-01-04 19:38:40,339 INFO    :  -->>[001/001][150/938][Time Left: 00:26:27] Average Loss: 0.535385, L0: 1.441, L1: 0.022, L2: 0.215, L3: 1.381, L4: 0.020, L5: 0.213, L6: 1.353, L7: 0.020, L8: 0.213, L9: 1.314, L10: 0.020, L11: 0.213
2024-01-04 19:38:59,308 INFO    :  -->>[001/001][160/938][Time Left: 00:26:01] Average Loss: 0.523757, L0: 1.417, L1: 0.022, L2: 0.196, L3: 1.355, L4: 0.019, L5: 0.194, L6: 1.338, L7: 0.019, L8: 0.193, L9: 1.322, L10: 0.019, L11: 0.193
2024-01-04 19:39:18,235 INFO    :  -->>[001/001][170/938][Time Left: 00:25:35] Average Loss: 0.499906, L0: 1.317, L1: 0.021, L2: 0.217, L3: 1.245, L4: 0.019, L5: 0.215, L6: 1.242, L7: 0.019, L8: 0.215, L9: 1.257, L10: 0.019, L11: 0.214
2024-01-04 19:39:37,286 INFO    :  -->>[001/001][180/938][Time Left: 00:25:10] Average Loss: 0.465207, L0: 1.245, L1: 0.021, L2: 0.233, L3: 1.099, L4: 0.019, L5: 0.231, L6: 1.116, L7: 0.019, L8: 0.230, L9: 1.121, L10: 0.019, L11: 0.230
2024-01-04 19:39:56,675 INFO    :  -->>[001/001][190/938][Time Left: 00:24:47] Average Loss: 0.450848, L0: 1.191, L1: 0.021, L2: 0.218, L3: 1.108, L4: 0.019, L5: 0.217, L6: 1.072, L7: 0.019, L8: 0.217, L9: 1.094, L10: 0.019, L11: 0.216
2024-01-04 19:40:16,169 INFO    :  -->>[001/001][200/938][Time Left: 00:24:25] Average Loss: 0.565056, L0: 1.526, L1: 0.020, L2: 0.219, L3: 1.441, L4: 0.018, L5: 0.218, L6: 1.435, L7: 0.018, L8: 0.217, L9: 1.433, L10: 0.018, L11: 0.217
2024-01-04 19:40:35,285 INFO    :  -->>[001/001][210/938][Time Left: 00:24:02] Average Loss: 0.491994, L0: 1.246, L1: 0.020, L2: 0.232, L3: 1.202, L4: 0.018, L5: 0.229, L6: 1.216, L7: 0.018, L8: 0.228, L9: 1.249, L10: 0.018, L11: 0.228
2024-01-04 19:40:54,938 INFO    :  -->>[001/001][220/938][Time Left: 00:23:41] Average Loss: 0.454515, L0: 1.160, L1: 0.020, L2: 0.232, L3: 1.120, L4: 0.018, L5: 0.231, L6: 1.067, L7: 0.018, L8: 0.230, L9: 1.111, L10: 0.018, L11: 0.230
2024-01-04 19:41:14,017 INFO    :  -->>[001/001][230/938][Time Left: 00:23:19] Average Loss: 0.509505, L0: 1.333, L1: 0.020, L2: 0.207, L3: 1.282, L4: 0.018, L5: 0.205, L6: 1.296, L7: 0.018, L8: 0.205, L9: 1.307, L10: 0.018, L11: 0.205
2024-01-04 19:41:32,830 INFO    :  -->>[001/001][240/938][Time Left: 00:22:56] Average Loss: 0.479161, L0: 1.287, L1: 0.019, L2: 0.230, L3: 1.155, L4: 0.017, L5: 0.227, L6: 1.153, L7: 0.017, L8: 0.226, L9: 1.175, L10: 0.017, L11: 0.226
2024-01-04 19:41:51,898 INFO    :  -->>[001/001][250/938][Time Left: 00:22:34] Average Loss: 0.477297, L0: 1.286, L1: 0.019, L2: 0.213, L3: 1.188, L4: 0.018, L5: 0.211, L6: 1.173, L7: 0.017, L8: 0.210, L9: 1.167, L10: 0.017, L11: 0.209
2024-01-04 19:42:11,033 INFO    :  -->>[001/001][260/938][Time Left: 00:22:12] Average Loss: 0.449796, L0: 1.178, L1: 0.019, L2: 0.238, L3: 1.135, L4: 0.017, L5: 0.234, L6: 1.040, L7: 0.017, L8: 0.233, L9: 1.034, L10: 0.017, L11: 0.233
2024-01-04 19:42:30,128 INFO    :  -->>[001/001][270/938][Time Left: 00:21:51] Average Loss: 0.426887, L0: 1.097, L1: 0.019, L2: 0.211, L3: 1.033, L4: 0.017, L5: 0.208, L6: 1.035, L7: 0.017, L8: 0.207, L9: 1.053, L10: 0.017, L11: 0.207
2024-01-04 19:42:49,017 INFO    :  -->>[001/001][280/938][Time Left: 00:21:29] Average Loss: 0.489324, L0: 1.344, L1: 0.019, L2: 0.226, L3: 1.232, L4: 0.018, L5: 0.224, L6: 1.170, L7: 0.018, L8: 0.223, L9: 1.159, L10: 0.018, L11: 0.223
2024-01-04 19:43:08,866 INFO    :  -->>[001/001][290/938][Time Left: 00:21:10] Average Loss: 0.516988, L0: 1.364, L1: 0.018, L2: 0.219, L3: 1.318, L4: 0.017, L5: 0.216, L6: 1.277, L7: 0.017, L8: 0.215, L9: 1.311, L10: 0.017, L11: 0.215
2024-01-04 19:43:28,433 INFO    :  -->>[001/001][300/938][Time Left: 00:20:50] Average Loss: 0.457519, L0: 1.214, L1: 0.019, L2: 0.235, L3: 1.114, L4: 0.017, L5: 0.234, L6: 1.084, L7: 0.017, L8: 0.232, L9: 1.075, L10: 0.017, L11: 0.232
2024-01-04 19:43:48,140 INFO    :  -->>[001/001][310/938][Time Left: 00:20:30] Average Loss: 0.387559, L0: 1.053, L1: 0.019, L2: 0.211, L3: 0.934, L4: 0.017, L5: 0.208, L6: 0.902, L7: 0.017, L8: 0.207, L9: 0.858, L10: 0.017, L11: 0.207
2024-01-04 19:44:07,172 INFO    :  -->>[001/001][320/938][Time Left: 00:20:09] Average Loss: 0.494791, L0: 1.344, L1: 0.018, L2: 0.207, L3: 1.268, L4: 0.017, L5: 0.204, L6: 1.227, L7: 0.017, L8: 0.204, L9: 1.212, L10: 0.017, L11: 0.203
2024-01-04 19:44:26,260 INFO    :  -->>[001/001][330/938][Time Left: 00:19:48] Average Loss: 0.445431, L0: 1.252, L1: 0.018, L2: 0.211, L3: 1.088, L4: 0.017, L5: 0.208, L6: 1.049, L7: 0.017, L8: 0.209, L9: 1.051, L10: 0.017, L11: 0.209
2024-01-04 19:44:45,253 INFO    :  -->>[001/001][340/938][Time Left: 00:19:27] Average Loss: 0.421159, L0: 1.206, L1: 0.018, L2: 0.218, L3: 1.018, L4: 0.017, L5: 0.215, L6: 0.968, L7: 0.017, L8: 0.215, L9: 0.932, L10: 0.017, L11: 0.214
2024-01-04 19:45:04,053 INFO    :  -->>[001/001][350/938][Time Left: 00:19:06] Average Loss: 0.485483, L0: 1.301, L1: 0.018, L2: 0.211, L3: 1.248, L4: 0.016, L5: 0.209, L6: 1.180, L7: 0.016, L8: 0.208, L9: 1.193, L10: 0.016, L11: 0.209
2024-01-04 19:45:22,817 INFO    :  -->>[001/001][360/938][Time Left: 00:18:45] Average Loss: 0.472069, L0: 1.273, L1: 0.018, L2: 0.208, L3: 1.236, L4: 0.017, L5: 0.205, L6: 1.114, L7: 0.017, L8: 0.205, L9: 1.149, L10: 0.017, L11: 0.205
2024-01-04 19:45:41,495 INFO    :  -->>[001/001][370/938][Time Left: 00:18:24] Average Loss: 0.410618, L0: 1.224, L1: 0.018, L2: 0.212, L3: 0.992, L4: 0.016, L5: 0.209, L6: 0.911, L7: 0.016, L8: 0.209, L9: 0.896, L10: 0.016, L11: 0.209
2024-01-04 19:46:00,350 INFO    :  -->>[001/001][380/938][Time Left: 00:18:04] Average Loss: 0.425768, L0: 1.122, L1: 0.018, L2: 0.200, L3: 0.990, L4: 0.017, L5: 0.196, L6: 1.071, L7: 0.017, L8: 0.196, L9: 1.070, L10: 0.017, L11: 0.196
2024-01-04 19:46:19,519 INFO    :  -->>[001/001][390/938][Time Left: 00:17:44] Average Loss: 0.448350, L0: 1.255, L1: 0.018, L2: 0.198, L3: 1.118, L4: 0.016, L5: 0.196, L6: 1.080, L7: 0.016, L8: 0.194, L9: 1.077, L10: 0.016, L11: 0.195
2024-01-04 19:46:38,461 INFO    :  -->>[001/001][400/938][Time Left: 00:17:23] Average Loss: 0.508208, L0: 1.370, L1: 0.018, L2: 0.225, L3: 1.259, L4: 0.017, L5: 0.222, L6: 1.270, L7: 0.017, L8: 0.222, L9: 1.243, L10: 0.017, L11: 0.221
2024-01-04 19:46:57,964 INFO    :  -->>[001/001][410/938][Time Left: 00:17:04] Average Loss: 0.429947, L0: 1.216, L1: 0.017, L2: 0.209, L3: 1.037, L4: 0.016, L5: 0.205, L6: 1.010, L7: 0.016, L8: 0.204, L9: 1.008, L10: 0.016, L11: 0.204
2024-01-04 19:47:17,219 INFO    :  -->>[001/001][420/938][Time Left: 00:16:44] Average Loss: 0.467772, L0: 1.313, L1: 0.017, L2: 0.205, L3: 1.184, L4: 0.017, L5: 0.203, L6: 1.125, L7: 0.016, L8: 0.202, L9: 1.113, L10: 0.016, L11: 0.202
2024-01-04 19:47:36,271 INFO    :  -->>[001/001][430/938][Time Left: 00:16:24] Average Loss: 0.422315, L0: 1.143, L1: 0.018, L2: 0.219, L3: 1.040, L4: 0.017, L5: 0.217, L6: 0.976, L7: 0.017, L8: 0.214, L9: 0.977, L10: 0.017, L11: 0.214
2024-01-04 19:47:55,194 INFO    :  -->>[001/001][440/938][Time Left: 00:16:04] Average Loss: 0.432141, L0: 1.185, L1: 0.017, L2: 0.203, L3: 1.143, L4: 0.016, L5: 0.201, L6: 1.043, L7: 0.016, L8: 0.199, L9: 0.948, L10: 0.016, L11: 0.199
2024-01-04 19:48:14,237 INFO    :  -->>[001/001][450/938][Time Left: 00:15:44] Average Loss: 0.494926, L0: 1.401, L1: 0.017, L2: 0.203, L3: 1.213, L4: 0.016, L5: 0.199, L6: 1.241, L7: 0.016, L8: 0.200, L9: 1.217, L10: 0.016, L11: 0.199
2024-01-04 19:48:33,238 INFO    :  -->>[001/001][460/938][Time Left: 00:15:24] Average Loss: 0.370461, L0: 1.062, L1: 0.017, L2: 0.232, L3: 0.864, L4: 0.016, L5: 0.230, L6: 0.761, L7: 0.016, L8: 0.228, L9: 0.775, L10: 0.016, L11: 0.227
2024-01-04 19:48:52,277 INFO    :  -->>[001/001][470/938][Time Left: 00:15:04] Average Loss: 0.498981, L0: 1.391, L1: 0.017, L2: 0.204, L3: 1.315, L4: 0.016, L5: 0.202, L6: 1.180, L7: 0.016, L8: 0.202, L9: 1.226, L10: 0.016, L11: 0.202
2024-01-04 19:49:11,031 INFO    :  -->>[001/001][480/938][Time Left: 00:14:44] Average Loss: 0.386643, L0: 1.081, L1: 0.016, L2: 0.224, L3: 0.917, L4: 0.016, L5: 0.222, L6: 0.823, L7: 0.016, L8: 0.220, L9: 0.869, L10: 0.016, L11: 0.220
2024-01-04 19:49:30,299 INFO    :  -->>[001/001][490/938][Time Left: 00:14:25] Average Loss: 0.404333, L0: 1.095, L1: 0.017, L2: 0.219, L3: 0.924, L4: 0.016, L5: 0.216, L6: 0.924, L7: 0.016, L8: 0.216, L9: 0.978, L10: 0.016, L11: 0.215
2024-01-04 19:49:49,978 INFO    :  -->>[001/001][500/938][Time Left: 00:14:05] Average Loss: 0.415589, L0: 1.223, L1: 0.017, L2: 0.224, L3: 0.980, L4: 0.016, L5: 0.221, L6: 0.932, L7: 0.016, L8: 0.220, L9: 0.901, L10: 0.016, L11: 0.220
2024-01-04 19:50:09,404 INFO    :  -->>[001/001][510/938][Time Left: 00:13:46] Average Loss: 0.430723, L0: 1.057, L1: 0.017, L2: 0.212, L3: 1.094, L4: 0.016, L5: 0.208, L6: 1.056, L7: 0.016, L8: 0.208, L9: 1.061, L10: 0.016, L11: 0.208
2024-01-04 19:50:28,897 INFO    :  -->>[001/001][520/938][Time Left: 00:13:27] Average Loss: 0.388944, L0: 1.135, L1: 0.017, L2: 0.214, L3: 0.950, L4: 0.016, L5: 0.211, L6: 0.824, L7: 0.016, L8: 0.209, L9: 0.851, L10: 0.016, L11: 0.210
2024-01-04 19:50:48,274 INFO    :  -->>[001/001][530/938][Time Left: 00:13:07] Average Loss: 0.388274, L0: 1.115, L1: 0.016, L2: 0.202, L3: 0.934, L4: 0.016, L5: 0.199, L6: 0.861, L7: 0.016, L8: 0.197, L9: 0.891, L10: 0.016, L11: 0.197
2024-01-04 19:51:07,385 INFO    :  -->>[001/001][540/938][Time Left: 00:12:48] Average Loss: 0.374947, L0: 1.053, L1: 0.017, L2: 0.212, L3: 0.872, L4: 0.016, L5: 0.210, L6: 0.839, L7: 0.016, L8: 0.208, L9: 0.833, L10: 0.016, L11: 0.207
2024-01-04 19:51:26,360 INFO    :  -->>[001/001][550/938][Time Left: 00:12:28] Average Loss: 0.343032, L0: 0.974, L1: 0.017, L2: 0.214, L3: 0.787, L4: 0.016, L5: 0.212, L6: 0.733, L7: 0.016, L8: 0.211, L9: 0.711, L10: 0.016, L11: 0.211
2024-01-04 19:51:45,697 INFO    :  -->>[001/001][560/938][Time Left: 00:12:08] Average Loss: 0.471996, L0: 1.306, L1: 0.016, L2: 0.208, L3: 1.202, L4: 0.016, L5: 0.204, L6: 1.153, L7: 0.015, L8: 0.203, L9: 1.124, L10: 0.015, L11: 0.202
2024-01-04 19:52:04,612 INFO    :  -->>[001/001][570/938][Time Left: 00:11:49] Average Loss: 0.323188, L0: 0.904, L1: 0.016, L2: 0.213, L3: 0.742, L4: 0.016, L5: 0.210, L6: 0.668, L7: 0.016, L8: 0.208, L9: 0.663, L10: 0.016, L11: 0.208
2024-01-04 19:52:23,594 INFO    :  -->>[001/001][580/938][Time Left: 00:11:29] Average Loss: 0.392835, L0: 1.120, L1: 0.017, L2: 0.202, L3: 0.964, L4: 0.016, L5: 0.199, L6: 0.895, L7: 0.016, L8: 0.197, L9: 0.876, L10: 0.016, L11: 0.197
2024-01-04 19:52:42,523 INFO    :  -->>[001/001][590/938][Time Left: 00:11:10] Average Loss: 0.389133, L0: 1.153, L1: 0.016, L2: 0.210, L3: 0.919, L4: 0.015, L5: 0.206, L6: 0.868, L7: 0.015, L8: 0.206, L9: 0.842, L10: 0.015, L11: 0.205
2024-01-04 19:53:02,388 INFO    :  -->>[001/001][600/938][Time Left: 00:10:50] Average Loss: 0.325046, L0: 0.909, L1: 0.017, L2: 0.217, L3: 0.705, L4: 0.016, L5: 0.212, L6: 0.690, L7: 0.016, L8: 0.210, L9: 0.682, L10: 0.016, L11: 0.211
2024-01-04 19:53:21,850 INFO    :  -->>[001/001][610/938][Time Left: 00:10:31] Average Loss: 0.322810, L0: 0.907, L1: 0.016, L2: 0.220, L3: 0.705, L4: 0.015, L5: 0.215, L6: 0.686, L7: 0.015, L8: 0.214, L9: 0.652, L10: 0.015, L11: 0.213
2024-01-04 19:53:42,156 INFO    :  -->>[001/001][620/938][Time Left: 00:10:12] Average Loss: 0.342639, L0: 1.039, L1: 0.017, L2: 0.199, L3: 0.749, L4: 0.016, L5: 0.196, L6: 0.752, L7: 0.016, L8: 0.195, L9: 0.723, L10: 0.016, L11: 0.194
2024-01-04 19:54:01,085 INFO    :  -->>[001/001][630/938][Time Left: 00:09:53] Average Loss: 0.410882, L0: 1.182, L1: 0.016, L2: 0.209, L3: 0.956, L4: 0.016, L5: 0.206, L6: 0.960, L7: 0.015, L8: 0.205, L9: 0.945, L10: 0.015, L11: 0.205
2024-01-04 19:54:19,934 INFO    :  -->>[001/001][640/938][Time Left: 00:09:33] Average Loss: 0.460916, L0: 1.279, L1: 0.016, L2: 0.204, L3: 1.127, L4: 0.016, L5: 0.202, L6: 1.128, L7: 0.016, L8: 0.201, L9: 1.127, L10: 0.015, L11: 0.201
2024-01-04 19:54:38,927 INFO    :  -->>[001/001][650/938][Time Left: 00:09:14] Average Loss: 0.387439, L0: 1.010, L1: 0.016, L2: 0.215, L3: 0.925, L4: 0.016, L5: 0.214, L6: 0.885, L7: 0.016, L8: 0.213, L9: 0.910, L10: 0.016, L11: 0.213
2024-01-04 19:54:58,123 INFO    :  -->>[001/001][660/938][Time Left: 00:08:54] Average Loss: 0.407679, L0: 1.148, L1: 0.016, L2: 0.209, L3: 1.021, L4: 0.016, L5: 0.206, L6: 0.925, L7: 0.015, L8: 0.203, L9: 0.914, L10: 0.015, L11: 0.203
2024-01-04 19:55:17,224 INFO    :  -->>[001/001][670/938][Time Left: 00:08:35] Average Loss: 0.342347, L0: 0.929, L1: 0.016, L2: 0.217, L3: 0.789, L4: 0.015, L5: 0.214, L6: 0.714, L7: 0.015, L8: 0.213, L9: 0.756, L10: 0.015, L11: 0.214
2024-01-04 19:55:36,055 INFO    :  -->>[001/001][680/938][Time Left: 00:08:15] Average Loss: 0.400344, L0: 1.101, L1: 0.016, L2: 0.231, L3: 0.943, L4: 0.016, L5: 0.229, L6: 0.911, L7: 0.016, L8: 0.227, L9: 0.872, L10: 0.015, L11: 0.227
2024-01-04 19:55:55,075 INFO    :  -->>[001/001][690/938][Time Left: 00:07:56] Average Loss: 0.411889, L0: 1.126, L1: 0.016, L2: 0.202, L3: 1.014, L4: 0.016, L5: 0.198, L6: 0.957, L7: 0.015, L8: 0.198, L9: 0.987, L10: 0.015, L11: 0.197
2024-01-04 19:56:14,774 INFO    :  -->>[001/001][700/938][Time Left: 00:07:37] Average Loss: 0.370756, L0: 1.077, L1: 0.016, L2: 0.197, L3: 0.879, L4: 0.015, L5: 0.193, L6: 0.821, L7: 0.015, L8: 0.193, L9: 0.832, L10: 0.015, L11: 0.194
2024-01-04 19:56:34,454 INFO    :  -->>[001/001][710/938][Time Left: 00:07:17] Average Loss: 0.405463, L0: 1.181, L1: 0.016, L2: 0.213, L3: 0.972, L4: 0.016, L5: 0.210, L6: 0.897, L7: 0.016, L8: 0.208, L9: 0.915, L10: 0.016, L11: 0.207
2024-01-04 19:56:53,964 INFO    :  -->>[001/001][720/938][Time Left: 00:06:58] Average Loss: 0.430089, L0: 1.149, L1: 0.016, L2: 0.211, L3: 1.106, L4: 0.015, L5: 0.210, L6: 1.020, L7: 0.015, L8: 0.209, L9: 0.989, L10: 0.015, L11: 0.208
2024-01-04 19:57:13,273 INFO    :  -->>[001/001][730/938][Time Left: 00:06:39] Average Loss: 0.389123, L0: 1.068, L1: 0.016, L2: 0.226, L3: 0.912, L4: 0.016, L5: 0.223, L6: 0.871, L7: 0.015, L8: 0.221, L9: 0.866, L10: 0.015, L11: 0.220
2024-01-04 19:57:32,069 INFO    :  -->>[001/001][740/938][Time Left: 00:06:19] Average Loss: 0.354286, L0: 1.073, L1: 0.016, L2: 0.211, L3: 0.787, L4: 0.016, L5: 0.206, L6: 0.783, L7: 0.016, L8: 0.203, L9: 0.723, L10: 0.015, L11: 0.203
2024-01-04 19:57:51,369 INFO    :  -->>[001/001][750/938][Time Left: 00:06:00] Average Loss: 0.343669, L0: 0.863, L1: 0.016, L2: 0.214, L3: 0.813, L4: 0.015, L5: 0.211, L6: 0.784, L7: 0.015, L8: 0.211, L9: 0.759, L10: 0.015, L11: 0.209
2024-01-04 19:58:10,309 INFO    :  -->>[001/001][760/938][Time Left: 00:05:41] Average Loss: 0.408309, L0: 1.106, L1: 0.016, L2: 0.218, L3: 1.006, L4: 0.016, L5: 0.213, L6: 0.983, L7: 0.016, L8: 0.212, L9: 0.888, L10: 0.016, L11: 0.211
2024-01-04 19:58:29,138 INFO    :  -->>[001/001][770/938][Time Left: 00:05:21] Average Loss: 0.374774, L0: 1.056, L1: 0.016, L2: 0.221, L3: 0.861, L4: 0.015, L5: 0.216, L6: 0.806, L7: 0.015, L8: 0.214, L9: 0.848, L10: 0.015, L11: 0.213
2024-01-04 19:58:48,332 INFO    :  -->>[001/001][780/938][Time Left: 00:05:02] Average Loss: 0.407134, L0: 1.087, L1: 0.016, L2: 0.203, L3: 0.988, L4: 0.015, L5: 0.198, L6: 1.004, L7: 0.015, L8: 0.196, L9: 0.953, L10: 0.015, L11: 0.196
2024-01-04 19:59:07,491 INFO    :  -->>[001/001][790/938][Time Left: 00:04:43] Average Loss: 0.420945, L0: 1.172, L1: 0.016, L2: 0.205, L3: 1.064, L4: 0.015, L5: 0.199, L6: 1.004, L7: 0.015, L8: 0.197, L9: 0.952, L10: 0.015, L11: 0.198
2024-01-04 19:59:26,944 INFO    :  -->>[001/001][800/938][Time Left: 00:04:23] Average Loss: 0.311483, L0: 0.881, L1: 0.016, L2: 0.204, L3: 0.693, L4: 0.015, L5: 0.199, L6: 0.663, L7: 0.015, L8: 0.198, L9: 0.641, L10: 0.015, L11: 0.196
2024-01-04 19:59:46,491 INFO    :  -->>[001/001][810/938][Time Left: 00:04:04] Average Loss: 0.416403, L0: 1.136, L1: 0.016, L2: 0.207, L3: 1.022, L4: 0.015, L5: 0.203, L6: 0.981, L7: 0.015, L8: 0.202, L9: 0.983, L10: 0.015, L11: 0.201
2024-01-04 20:00:05,881 INFO    :  -->>[001/001][820/938][Time Left: 00:03:45] Average Loss: 0.345824, L0: 0.999, L1: 0.015, L2: 0.201, L3: 0.819, L4: 0.015, L5: 0.196, L6: 0.764, L7: 0.014, L8: 0.194, L9: 0.725, L10: 0.014, L11: 0.193
2024-01-04 20:00:24,912 INFO    :  -->>[001/001][830/938][Time Left: 00:03:26] Average Loss: 0.351486, L0: 0.946, L1: 0.016, L2: 0.200, L3: 0.793, L4: 0.016, L5: 0.198, L6: 0.796, L7: 0.016, L8: 0.197, L9: 0.827, L10: 0.016, L11: 0.197
2024-01-04 20:00:43,896 INFO    :  -->>[001/001][840/938][Time Left: 00:03:06] Average Loss: 0.372675, L0: 1.103, L1: 0.016, L2: 0.201, L3: 0.885, L4: 0.015, L5: 0.195, L6: 0.838, L7: 0.015, L8: 0.193, L9: 0.805, L10: 0.015, L11: 0.192
2024-01-04 20:01:02,400 INFO    :  -->>[001/001][850/938][Time Left: 00:02:47] Average Loss: 0.330409, L0: 1.000, L1: 0.016, L2: 0.198, L3: 0.740, L4: 0.015, L5: 0.191, L6: 0.706, L7: 0.015, L8: 0.190, L9: 0.688, L10: 0.015, L11: 0.189
2024-01-04 20:01:21,317 INFO    :  -->>[001/001][860/938][Time Left: 00:02:28] Average Loss: 0.364031, L0: 1.090, L1: 0.016, L2: 0.218, L3: 0.834, L4: 0.015, L5: 0.211, L6: 0.791, L7: 0.015, L8: 0.211, L9: 0.744, L10: 0.015, L11: 0.209
2024-01-04 20:01:40,149 INFO    :  -->>[001/001][870/938][Time Left: 00:02:08] Average Loss: 0.357066, L0: 1.003, L1: 0.016, L2: 0.212, L3: 0.844, L4: 0.015, L5: 0.208, L6: 0.777, L7: 0.015, L8: 0.206, L9: 0.769, L10: 0.015, L11: 0.205
2024-01-04 20:01:59,176 INFO    :  -->>[001/001][880/938][Time Left: 00:01:49] Average Loss: 0.384806, L0: 1.082, L1: 0.015, L2: 0.209, L3: 0.894, L4: 0.015, L5: 0.204, L6: 0.881, L7: 0.015, L8: 0.202, L9: 0.885, L10: 0.015, L11: 0.202
2024-01-04 20:02:17,971 INFO    :  -->>[001/001][890/938][Time Left: 00:01:30] Average Loss: 0.336628, L0: 0.972, L1: 0.016, L2: 0.212, L3: 0.802, L4: 0.016, L5: 0.208, L6: 0.680, L7: 0.015, L8: 0.204, L9: 0.697, L10: 0.015, L11: 0.203
2024-01-04 20:02:37,117 INFO    :  -->>[001/001][900/938][Time Left: 00:01:11] Average Loss: 0.321805, L0: 0.872, L1: 0.016, L2: 0.219, L3: 0.717, L4: 0.016, L5: 0.214, L6: 0.671, L7: 0.016, L8: 0.212, L9: 0.681, L10: 0.016, L11: 0.212
2024-01-04 20:02:55,461 INFO    :  -->>[001/001][910/938][Time Left: 00:00:51] Average Loss: 0.338774, L0: 0.975, L1: 0.016, L2: 0.197, L3: 0.839, L4: 0.016, L5: 0.193, L6: 0.714, L7: 0.015, L8: 0.190, L9: 0.706, L10: 0.015, L11: 0.189
2024-01-04 20:03:11,316 INFO    :  -->>[001/001][920/938][Time Left: 00:00:32] Average Loss: 0.321589, L0: 0.934, L1: 0.015, L2: 0.211, L3: 0.731, L4: 0.015, L5: 0.205, L6: 0.657, L7: 0.015, L8: 0.202, L9: 0.659, L10: 0.015, L11: 0.201
2024-01-04 20:03:27,352 INFO    :  -->>[001/001][930/938][Time Left: 00:00:13] Average Loss: 0.355612, L0: 1.002, L1: 0.015, L2: 0.202, L3: 0.842, L4: 0.015, L5: 0.198, L6: 0.791, L7: 0.015, L8: 0.197, L9: 0.779, L10: 0.015, L11: 0.197
2024-01-04 20:03:39,651 INFO    :  -->>[001/001][937/938][Time Left: 00:00:00] Average Loss: 0.287045, L0: 0.757, L1: 0.015, L2: 0.225, L3: 0.623, L4: 0.015, L5: 0.217, L6: 0.561, L7: 0.015, L8: 0.215, L9: 0.572, L10: 0.015, L11: 0.214
2024-01-04 20:03:40,293 INFO    : Train/Epoch: 1/1, Average total time cost per iteration in this epoch: 1.938812
2024-01-04 20:03:40,293 INFO    : Train/Epoch: 1/1, Average loading data time cost per iteration in this epoch: 0.026248
2024-01-04 20:03:40,293 INFO    : Train/Epoch: 1/1, Average training model time cost per iteration in this epoch: 1.912564
2024-01-04 20:03:40,293 INFO    : Train/Epoch: 1/1, Average Loss in this epoch: 0.468220
2024-01-04 20:03:40,293 INFO    : Train/Loss000 in this epoch: 1.265432
2024-01-04 20:03:40,293 INFO    : Train/Loss001 in this epoch: 0.052284
2024-01-04 20:03:40,293 INFO    : Train/Loss002 in this epoch: 0.246820
2024-01-04 20:03:40,294 INFO    : Train/Loss003 in this epoch: 1.110367
2024-01-04 20:03:40,294 INFO    : Train/Loss004 in this epoch: 0.044415
2024-01-04 20:03:40,294 INFO    : Train/Loss005 in this epoch: 0.237414
2024-01-04 20:03:40,294 INFO    : Train/Loss006 in this epoch: 1.058790
2024-01-04 20:03:40,294 INFO    : Train/Loss007 in this epoch: 0.043659
2024-01-04 20:03:40,294 INFO    : Train/Loss008 in this epoch: 0.237005
2024-01-04 20:03:40,294 INFO    : Train/Loss009 in this epoch: 1.044836
2024-01-04 20:03:40,294 INFO    : Train/Loss010 in this epoch: 0.044182
2024-01-04 20:03:40,294 INFO    : Train/Loss011 in this epoch: 0.233442
2024-01-04 20:03:40,331 INFO    : Forward process, Dataset size: 2499, Batch size: 32
100% 79/79 [03:48<00:00,  2.90s/it]
/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.
  return _methods._mean(a, axis=axis, dtype=dtype,
/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
/content/drive/MyDrive/colab/star/lib/metric/fr_and_auc.py:22: RuntimeWarning: invalid value encountered in divide
  ys = np.array([np.count_nonzero(nmes <= x) for x in xs]) / float(num_data)
2024-01-04 20:07:29,843 INFO    : Val_net/Metric  0 in this epoch: [NME 0.172320, FR 0.735500, AUC 0.038478]
2024-01-04 20:07:29,843 INFO    : Val_net/Metric  1 in this epoch: [NME nan, FR nan, AUC nan]
2024-01-04 20:07:29,843 INFO    : Val_net/Metric  2 in this epoch: [NME nan, FR nan, AUC nan]
2024-01-04 20:07:29,843 INFO    : Val_net/Metric  3 in this epoch: [NME 0.148530, FR 0.666300, AUC 0.054851]
2024-01-04 20:07:29,843 INFO    : Val_net/Metric  4 in this epoch: [NME nan, FR nan, AUC nan]
2024-01-04 20:07:29,843 INFO    : Val_net/Metric  5 in this epoch: [NME nan, FR nan, AUC nan]
2024-01-04 20:07:29,843 INFO    : Val_net/Metric  6 in this epoch: [NME 0.134317, FR 0.526600, AUC 0.099548]
2024-01-04 20:07:29,843 INFO    : Val_net/Metric  7 in this epoch: [NME nan, FR nan, AUC nan]
2024-01-04 20:07:29,843 INFO    : Val_net/Metric  8 in this epoch: [NME nan, FR nan, AUC nan]
2024-01-04 20:07:29,844 INFO    : Val_net/Metric  9 in this epoch: [NME 0.134098, FR 0.519800, AUC 0.097081]
2024-01-04 20:07:29,844 INFO    : Val_net/Metric 10 in this epoch: [NME nan, FR nan, AUC nan]
2024-01-04 20:07:29,844 INFO    : Val_net/Metric 11 in this epoch: [NME nan, FR nan, AUC nan]
2024-01-04 20:07:30,749 INFO    : Epoch: 1/1, model saved in this epoch
2024-01-04 20:07:30,777 INFO    : Forward process, Dataset size: 2499, Batch size: 32
100% 79/79 [03:53<00:00,  2.96s/it]
2024-01-04 20:11:25,118 INFO    : Val_net_ema/Metric  0 in this epoch: [NME 0.697704, FR 1.000000, AUC 0.000000]
2024-01-04 20:11:25,122 INFO    : Val_net_ema/Metric  1 in this epoch: [NME nan, FR nan, AUC nan]
2024-01-04 20:11:25,122 INFO    : Val_net_ema/Metric  2 in this epoch: [NME nan, FR nan, AUC nan]
2024-01-04 20:11:25,122 INFO    : Val_net_ema/Metric  3 in this epoch: [NME 0.665475, FR 1.000000, AUC 0.000000]
2024-01-04 20:11:25,122 INFO    : Val_net_ema/Metric  4 in this epoch: [NME nan, FR nan, AUC nan]
2024-01-04 20:11:25,122 INFO    : Val_net_ema/Metric  5 in this epoch: [NME nan, FR nan, AUC nan]
2024-01-04 20:11:25,122 INFO    : Val_net_ema/Metric  6 in this epoch: [NME 0.547772, FR 1.000000, AUC 0.000000]
2024-01-04 20:11:25,122 INFO    : Val_net_ema/Metric  7 in this epoch: [NME nan, FR nan, AUC nan]
2024-01-04 20:11:25,122 INFO    : Val_net_ema/Metric  8 in this epoch: [NME nan, FR nan, AUC nan]
2024-01-04 20:11:25,122 INFO    : Val_net_ema/Metric  9 in this epoch: [NME 0.524611, FR 1.000000, AUC 0.000000]
2024-01-04 20:11:25,122 INFO    : Val_net_ema/Metric 10 in this epoch: [NME nan, FR nan, AUC nan]
2024-01-04 20:11:25,123 INFO    : Val_net_ema/Metric 11 in this epoch: [NME nan, FR nan, AUC nan]
2024-01-04 20:11:25,123 INFO    : Val/Best_Metric009 in this epoch: 0.134098
2024-01-04 20:11:27,679 INFO    : Epoch: 1/1, model saved in this epoch
2024-01-04 20:11:27,685 INFO    : Train/Epoch: 1/1, Learning rate decays to [0.001], [Time Left: 00:00:00]eval_time: 464.82, 


2024-01-04 20:11:27,687 INFO    : Training finished